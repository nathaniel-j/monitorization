{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![monitor](monitor_pic.jpg)\n",
    "\n",
    "\n",
    "My current computer monitor is getting a bit dated and my eyes have started to feel sore from looking at it all day. I want to buy a new computer monitor, but every time I get online to start searching I get overwhelmed by the number of monitors available. They come in a wide variety of sizes, widths, definitions, display types, port types, etc, and vary in price from under \\\\$100 to well over \\\\$1000. While I know that I want to upgrade my screen size to give me more working area, other options, like gaming features, are irrelevant to me. How on earth will I ever be able to decide which monitor is right for me?\n",
    "\n",
    "This seems like a perfect opportunity to put some data analysis into action! For this project I am going to be acquiring feature data for a number of different computer monitors and running some product analysis across those features to help me make a data driven decision which monitor to purchase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: Get the data\n",
    "Unfortunately, I was unable to find a downloadable preexisting dataset for computer monitors so I had to make the dataset myself. I looked through a few different websites that carried a wide variety of monitors from different manufacturers but the available data was limited to pretty basic specifications. For this project I wanted to use a dataset with a rich feature set in order to try to explore more subtle differences in features and try to tease out their value. LG is one of the brands that seem to be pretty appealing to me, and when I looked at their website I found that for each monitor they provided over 50 data points and it was in a format that wouldnt be too difficult to scrape. So, my first step of the first step is going to be building a set of functions to scrape, clean and format the data for one monitor into a dataframe. Then later I will use those functions across multiple monitors and compile them all into one dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor URL list\n",
    "I am starting by extracting the URL for each monitor into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format for our monitor URLs in the list: https://www.lg.com/us/monitors/lg-27up650-w-4k-uhd-monitor\n"
     ]
    }
   ],
   "source": [
    "# extracting the list of monitor URLs to a list\n",
    "results = requests.get('https://www.lg.com/us/monitors')\n",
    "content = results.content\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "monitors = soup.find_all('a', class_='ga-model-detail')\n",
    "\n",
    "monitor_list = [monitor.get('href') for monitor in monitors]\n",
    "edited_monitor_list = monitor_list[2:46]\n",
    "reedited_list = []\n",
    "for m in edited_monitor_list:\n",
    "    if m not in reedited_list:\n",
    "        reedited_list.append(m)\n",
    "monitor_url_list = [monitor.rsplit('/',1)[1] for monitor in reedited_list]\n",
    "base_url = 'https://www.lg.com/us/monitors/'\n",
    "monitor_url_list = [base_url + monitor_extention for monitor_extention in monitor_url_list]\n",
    "\n",
    "print(f'This is the format for our monitor URLs in the list: {monitor_url_list[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual monitor data extraction\n",
    "Next step is building the functions that will extract and clean up the data for each monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned object is a <class 'list'> with 10 elements \n"
     ]
    }
   ],
   "source": [
    "# downloading the selected spec tags for a given monitor from the LG website\n",
    "\n",
    "results = requests.get('https://www.lg.com/us/monitors/lg-32ul500-w-4k-uhd-monitor')\n",
    "content = results.content\n",
    "parser = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "table = list(parser.find_all('div', class_=\"tech-spacs\"))\n",
    "\n",
    "# the result is a list with 10 elements\n",
    "# each element is a string with spec data for one aspect of the monitor\n",
    "\n",
    "table_type = type(table)\n",
    "print(f\"returned object is a {table_type} with {len(table)} elements \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the first element and turning it into a list\n",
    "\n",
    "first_table = table[0].text.replace('\\n', ' ')\n",
    "first_table = first_table.replace('\\t', ' ')\n",
    "first_table = first_table.strip()\n",
    "first_table_listed = first_table.rsplit('   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the list\n",
    "\n",
    "q_list = [element for element in first_table_listed if element != '']\n",
    "q_header = q_list[0]\n",
    "q_body = q_list[1:]\n",
    "f = lambda q: q.strip()\n",
    "mapped_q = list(map(f, q_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the list into category & value lists and recombining as a dictionary\n",
    "\n",
    "category = [mapped_q[i] for i in range(len(mapped_q)) if i%2 == 0]\n",
    "value = [mapped_q[i] for i in range(len(mapped_q)) if i%2 != 0]\n",
    "monitor_dict = dict(zip(category, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Display  Type</th>\n",
       "      <th>Response Time</th>\n",
       "      <th>Refresh Rate</th>\n",
       "      <th>Display Resolution</th>\n",
       "      <th>Color Gamut (Typ.)</th>\n",
       "      <th>Color Depth (Number of Colors)</th>\n",
       "      <th>Pixel Pitch (mm)</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Brightness</th>\n",
       "      <th>Contrast Ratio</th>\n",
       "      <th>Viewing Angle</th>\n",
       "      <th>Surface Treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32\"</td>\n",
       "      <td>VA</td>\n",
       "      <td>4ms (GtG at Faster)</td>\n",
       "      <td>60Hz</td>\n",
       "      <td>4K UHD</td>\n",
       "      <td>DCI-P3 95% (CIE1976)</td>\n",
       "      <td>1.07B</td>\n",
       "      <td>0.181x 0.181 mm</td>\n",
       "      <td>16:9</td>\n",
       "      <td>3840 x 2160</td>\n",
       "      <td>300cd/m²</td>\n",
       "      <td>3000:1</td>\n",
       "      <td>178˚(R/L), 178˚(U/D)</td>\n",
       "      <td>Anti-Glare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Size Display  Type        Response Time Refresh Rate Display Resolution  \\\n",
       "0  32\"            VA  4ms (GtG at Faster)         60Hz             4K UHD   \n",
       "\n",
       "     Color Gamut (Typ.) Color Depth (Number of Colors) Pixel Pitch (mm)  \\\n",
       "0  DCI-P3 95% (CIE1976)                          1.07B  0.181x 0.181 mm   \n",
       "\n",
       "  Aspect Ratio   Resolution Brightness Contrast Ratio         Viewing Angle  \\\n",
       "0         16:9  3840 x 2160   300cd/m²         3000:1  178˚(R/L), 178˚(U/D)   \n",
       "\n",
       "  Surface Treatment  \n",
       "0        Anti-Glare  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting the values into a dataframe with the row representing the monitor and columns are its attributes\n",
    "\n",
    "df = pd.DataFrame(data=monitor_dict, index=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together and building functions for the transformation of each returned scraped elements\n",
    "\n",
    "def download_monitor_specs(URL):\n",
    "    \"\"\"Import monitor specs and parse into list of strings\"\"\"\n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    results = requests.get(URL)\n",
    "    content = results.content\n",
    "    parser = BeautifulSoup(content, 'lxml')\n",
    "    list_of_strings = list(parser.find_all('div', class_=\"tech-spacs\"))\n",
    "    return list_of_strings\n",
    "    \n",
    "def clean_element(list_of_strings):\n",
    "    \"\"\"Reformat list of HTML strings and return a list of lists\"\"\"\n",
    "    \n",
    "    listed_element_lists = []\n",
    "    for string in list_of_strings:\n",
    "        string = string.text.replace('\\n', ' ')\n",
    "        string = string.replace('\\t', ' ')\n",
    "        string = string.strip()\n",
    "        listed_string = string.rsplit('   ')\n",
    "        listed_element_lists.append(listed_string)\n",
    "    return listed_element_lists\n",
    "\n",
    "def clean_listed_element(listed_element_lists):\n",
    "    \"\"\"Remove blank lines and strip empty spaces on list elements\"\"\"\n",
    "    \n",
    "    cleaned_element_list = []\n",
    "    for list_ in listed_element_lists:\n",
    "        listed_element = [element for element in list_ if element != '']\n",
    "        listed_element = listed_element[1:]\n",
    "        f = lambda q: q.strip()\n",
    "        listed_element = list(map(f, listed_element))\n",
    "        cleaned_element_list.append(listed_element)\n",
    "    return cleaned_element_list\n",
    "\n",
    "def list_to_dict(cleaned_element_list):\n",
    "    \"\"\"Separate list into categories and values then combine into dictionary\"\"\"\n",
    "    \n",
    "    categories = []\n",
    "    values = []\n",
    "    for element in cleaned_element_list:\n",
    "        category = [element[i] for i in range(len(element)) if i%2 == 0]\n",
    "        categories += category\n",
    "        value = [element[i] for i in range(len(element)) if i%2 != 0]\n",
    "        values+=value\n",
    "    \n",
    "    monitor_dict = dict(zip(categories, values))\n",
    "    return monitor_dict\n",
    "\n",
    "\n",
    "def dict_to_df(monitor_dict):\n",
    "    \"\"\"Convert dictionary of monitor specs into pandas DataFrame object\"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data=monitor_dict, index=[0])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 52)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing out the function pipeline so far\n",
    "\n",
    "url = 'https://www.lg.com/us/monitors/lg-32ul500-w-4k-uhd-monitor'\n",
    "\n",
    "df = dict_to_df(\n",
    "    list_to_dict(\n",
    "    clean_listed_element(\n",
    "    clean_element(\n",
    "    download_monitor_specs(url)\n",
    "    ))))\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting together secondary path for review page info retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for price, model name and reviews it was easier to scrape from a different URL than the initial scrape\n",
    "\n",
    "def access_review_page(url):\n",
    "    \"\"\"redirect monitor url to monitor review url\"\"\"\n",
    "    monitor_review_url = url + '/reviews'\n",
    "    \n",
    "    return monitor_review_url\n",
    "\n",
    "def extract_review_elements(monitor_review_url):\n",
    "    \"\"\"Pulls values from monitor review website and returns dict with 'col':'value' format\"\"\"\n",
    "    results = requests.get(monitor_review_url)\n",
    "    content = results.content\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    \n",
    "    values_to_extract = {\n",
    "        'model_name':'mpn',\n",
    "        'model_title':'name',\n",
    "        'price':'price',\n",
    "        'rating_count':\"reviewCount\",\n",
    "        'avg_rating':\"ratingValue\"\n",
    "    }\n",
    "    \n",
    "    for column in values_to_extract.keys():\n",
    "        label = values_to_extract[column]\n",
    "        extracted_html_value = soup.find('meta', {'itemprop':label})\n",
    "        extracted_value = extracted_html_value.get('content')\n",
    "        # update dictionary value with extracted value\n",
    "        values_to_extract[column]=extracted_value\n",
    "        \n",
    "    return values_to_extract\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "This part uses the list of monitors to retrieve all the data for each monitor and compiles it all together in one pandas dataframe so that I can get to work cleaning the data, and later perform some (hopefully) insightful analysis on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing a new dataframe outside the for loop to concatonate with\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# looping through the URL for each monitor\n",
    "for monitor in monitor_url_list:\n",
    "    # building dictionary from values on the monitor page\n",
    "    d = list_to_dict(\n",
    "    clean_listed_element(\n",
    "    clean_element(\n",
    "    download_monitor_specs(monitor)\n",
    "    )))\n",
    "    # building dictionary from values on the monitor review page\n",
    "    d2 = access_review_page(monitor)\n",
    "    d2 = extract_review_elements(d2)\n",
    "    # combining the dictionaries\n",
    "    d2.update(d)\n",
    "    # converting the dictionaries into a dataframe\n",
    "    df2 = pd.DataFrame(data=[d2])\n",
    "    # adding the monitor's dataframe row to the initial dataframe \n",
    "    df = pd.concat([df, df2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 174)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up an index\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On to data manipulation!\n",
    "Finally, I have a working dataframe, now its time to clean it up! Unfortunately there are only 19 monitors for my dataset, which doesnt give me a lot of comparison points to work with. However there are nearly 200 features! An awful lot of those will end up getting removed for lack of utility, and some of them will end up getting combined or transformed, but there should still be plenty of features to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
